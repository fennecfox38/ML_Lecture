{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5a2232",
   "metadata": {},
   "source": [
    "# IMDB dataset\n",
    "## from ```tensorflow.keras.datasets.imdb```\n",
    "\n",
    "![IMDB_Logo_2016.svg](https://upload.wikimedia.org/wikipedia/commons/6/69/IMDB_Logo_2016.svg)\n",
    "* is movie review data.\n",
    "* has 25000 of train data and 25000 of test data.\n",
    "* Its label is 1 if it is positive, or 0 if negative.\n",
    "\n",
    "This dataset gives preprocessed, numerized data.\n",
    "\n",
    "For practice,\n",
    "* take only 10000 of most frequent words.\n",
    "* learns only last 80 words in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551df8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# load data from tensorflow.keras.datasets.imdb\n",
    "max_features = 10000 # load only 10000 of most frequent words.\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(x_train[0]) # This is a sequence of expressions of sentiment about a certain movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883e87c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train[0]: [  15  256    4    2    7 3766    5  723   36   71   43  530  476   26\n",
      "  400  317   46    7    4    2 1029   13  104   88    4  381   15  297\n",
      "   98   32 2071   56   26  141    6  194 7486   18    4  226   22   21\n",
      "  134  476   26  480    5  144   30 5535   18   51   36   28  224   92\n",
      "   25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
      " 4472  113  103   32   15   16 5345   19  178   32] size of x_train[0]: 80\n",
      "y_train[0]: 1\n"
     ]
    }
   ],
   "source": [
    "maxlen=80\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen) # cutting last 80 words \n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print(\"x_train[0]:\", x_train[0], \"size of x_train[0]:\",len(x_train[0])) \n",
    "print(\"y_train[0]:\",y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae4baa",
   "metadata": {},
   "source": [
    "## Use embedding vector\n",
    "\n",
    "* 10000 one-hot vectors for 80 sequences would be 80000 size of input\n",
    "* Convert 10000 of one-hot vectors to 128 of embedding vectors\n",
    "    - Saving memory\n",
    "    - Explicating relationships between each word.\n",
    "* 128 LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce6d585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 101s 127ms/step - loss: 0.4332 - accuracy: 0.7927 - val_loss: 0.3682 - val_accuracy: 0.8393\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 100s 129ms/step - loss: 0.2796 - accuracy: 0.8865 - val_loss: 0.3606 - val_accuracy: 0.8386\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 100s 128ms/step - loss: 0.1932 - accuracy: 0.9248 - val_loss: 0.4949 - val_accuracy: 0.8192\n",
      "782/782 [==============================] - 23s 30ms/step - loss: 0.4949 - accuracy: 0.8192\n",
      "Test performance: accuracy=0.8192399740219116, loss=0.49490121006965637\n"
     ]
    }
   ],
   "source": [
    "x=layers.Input((maxlen,))\n",
    "h=layers.Embedding(max_features, 128)(x)\n",
    "h=layers.LSTM(128)(h)\n",
    "y=layers.Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model=models.Model(x,y)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size=32\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test performance: accuracy={0}, loss={1}'.format(acc, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df91f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of test[0]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[1]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[2]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[3]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[4]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[5]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[6]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[7]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[8]: [[0.03515437]] | y_test[0]: 0\n",
      "prediction of test[9]: [[0.03515437]] | y_test[0]: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "testSample = np.expand_dims(x_test[0], axis=0) \n",
    "pred = model.predict(testSample)\n",
    "for i in range(10):\n",
    "    print(\"prediction of test[{}]: {} | y_test[0]: {}\".format(i,pred,y_test[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
