{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Time Series Forcasting (시계열 예측)\n",
    "* In some cases, present state effects to next state.\n",
    "* Present state is made by previous state and present condition.\n",
    "* For example,\n",
    "    - Text auto-complete\n",
    "    - Heights of ocean tides\n",
    "    - Wind Velocity\n",
    "    - Counts of sunspots\n",
    "\n",
    "* AR(1) Model (Autoregressive):\n",
    "    - $Y_t = \\phi Y_{t-1} + \\epsilon_t$\n",
    "* ARIMA(1,1) Model (AutoRegessive Integrated Moving Average):\n",
    "    - $Y_t = \\phi Y_{t-1} + \\theta \\epsilon_{t-1} + \\epsilon_t$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN: Recurrent Neural Network (순환 신경망)\n",
    "* is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence.\n",
    "* can use their internal state (memory) to process variable length sequences of inputs.\n",
    "* sends the result from activation function in the node of the hidden layer to the output layer and sends it back to the input of the node in the hidden layer.\n",
    "* (cf. in Feedforward Neural Network, the values that passed the activation function in the hidden layer were directed only toward the output layer.)\n",
    "\n",
    "![simple_rnn.png](simple_rnn.png)\n",
    "\n",
    "Simple RNN Model (above) consists of input, output and hidden layer. It is called **Recurrent** Neural Network because output of the node is used as input of the node as it is shown.\n",
    "\n",
    "At time $t$, $h$ is determined by $X$ at $t$ and $h$ at $t-1$. This can be expressed as:\n",
    "\n",
    "$$h_t = f(h_{t-1},x_t) = tanh(W_{hh}h_{t-1}+W_{xh}x_t)$$\n",
    "$$y_t = W_{hy}h_t$$\n",
    "\n",
    "tanh or ReLU are usually used as activation function because of  gradient vanishing prevention. Derivative of tanh is usually larger than sigmoid as it shown below.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "    e = np.exp(-x)\n",
    "    return e/((1+e)**2)\n",
    "\n",
    "def deriv_tanh(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "\n",
    "domain = np.linspace(-3,3,900)\n",
    "\n",
    "plt.subplot(211)\n",
    "func = plt.plot(domain, np.tanh(domain), label='tanh')\n",
    "deriv = plt.plot(domain, deriv_tanh(domain), label='derivative')\n",
    "plt.legend([func,deriv])\n",
    "\n",
    "plt.subplot(212)\n",
    "func = plt.plot(domain, sigmoid(domain), label='sigmoid')\n",
    "deriv = plt.plot(domain, deriv_sigmoid(domain), label='derivative')\n",
    "plt.legend([func,deriv])\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABfzElEQVR4nO2daXhV1dWA331v5nmGQCAJEIHMTAFEJiGgRRGoE8WKA7XWsX7VirWI1VpxqGNR64RoHVBUxBlUqCBSZgTCDIEEApnn6Q7r+3FuLgkECJDkJmG/z3OeM++z9r7nrrPO2uusrUQEjUaj0XRcTK4WQKPRaDQti1b0Go1G08HRil6j0Wg6OFrRazQaTQdHK3qNRqPp4Li5WoDjCQsLk5iYGFeLodFoNO2K9evX54tIeGP72pyij4mJYd26da4WQ6PRaNoVSqkDJ9vX4q4bpdSbSqlcpdTWlr6WRqPRaE6kNXz0bwGXtMJ1NBqNRtMILe66EZEflVIxLX0djaZZsFkgNwMOb4Tc7VCSDaWHobrE2Cd28PQDr0AIjILQXhAaB90GQVA0KOXqGmjOALtdqLXZqbHasdjs1Fodk+24eb3tFsfxVptgs9ux2gVb3SSCzSZY7YJdHHO7NDim/rb6x9jsQkyYLzMv7dPs9WwTPnql1C3ALQDdu3d3sTSa847iLNj1DexeAvtXgLXK2O7hZyjzgK4QEgtmT0OR15RBdTFkr4OtnwCONCL+XSB2OPS5DHqNAQ9fV9WoQ2O12SmttlJaZaG02kJJlYXSKmu9ZQuVtTYqa61U1tqoqrUZ6xYbVY5tdfurLfYWk9OkwGxSxqSMuZvZhEkp3Oq2O6a6Yz3dW8bJ0iYUvYi8CrwKMHDgQJ18R9Py1FbC9sWw6V3Y/6OxLTgW+l8P3QdDl37G+uksdGsN5O+Cg6vhwCrYvRR+WQBu3tD3Mhh4E3Qfqi3901BtsXGkpJojpdXkl9eQX1ZDfnktBRU15JXVGtvKayiqqKWi1nbKstxMCh8PMz4ebvh4mPH2MOPjYSbQ253IAK8G27w93PByN+FhNuHhVm/uWHZ3M+FZf5ubCXezY5/ZZChvk8JsPqbM6xS7ydR2fvM2oeg1mlaj7Cj87xVY94bhjgmOgdEPQsIUCOt15uW5eULnJGNK+x3YrHDgJ8hYBFs+hi0fQXgfSLsFUqeBu1dz16hdYLHZOVhYyb68CrIKKzlcXMXhkioOFVVxqNhQ7sdjUhDi60mYnwfh/p7EhvkS7ONBoLc7gd5uBHi7E+DlTqCPMQ/wdiPQ2x1vdzNKP1gboFoje6XDR/+FiCSe7tiBAweKDq/UNDtFB2DFP2Hz+4avPX4ipP0eoi9sOWu7tgK2fQprXzd8/n6d4cI7YeCNHdatU1lrZceRMnbklLEvr5x9+RXsz6/gYGElNvsxXePlbqJrkDddgrwbzDsHehHm50monwfBPh6Y25BV3NZRSq0XkYGN7mtpRa+Ueh8YBYQBR4HZIvLGyY7Xil7TrFQUGAp+7WuAgn7TYOgdENqz9WQQMdxDPz4FmSvArxOM/gukXgfm9vtSXVJlYXNWMVsPl5BxuJSMnFL251dQp1I83UzEhvnSI9yXHmF+9Aj3JTbMl+hQX4J93LXV3cy4VNGfKVrRa5oFSzWsngsrn4PacsNtMuoBCOzqWrkOroalsyFrteHSSX8U4tLbvA9fRMgsqGT9gSLWHyhiw4EiduWWOZV6VLA38ZEBxHcJoG9kAPGRAXQN8m5TfuqOzqkUffs1JzSak7Hne/jqPijcCxdcCmNnQ0RfV0tl0H0I3PQNbP8cvpsN710FcePgV08Z/QVtiPzyGn7ak8+K3fms3J3PkdJqAPy93OjfPZgJyZH07x5MUlQggd7uLpZWcyq0otd0HEoPwzcPGB2hIT3huk+MMMe2hlJGH0HvS2HNq7DsHzB3MIz8Mwy9E9w8XCKWiLDtcCnfbjvC99tzycgpBSDQ251hvUIZ1iuMQTEh9Ar305Z6O0O7bjTtH7vd6PD8/m9gt8Lwe2HYXUZETHug5BB8M9MI9wzrDZc9CzHDWuXSdruwNrOQb7YdYcm2oxwqrsKkYGB0CCMuCGN4XDiJXQN1p2g7QLtuNB2Xwv2w+E6jk7PnGJjwT+PjpvZEYFe45h3Y9S18dS+89SsjHHPswy0WnbMnt5xPNmSzaOMhDpdU4+FmYnivMO4eE8eYvhGE+rWTh6SmSWhFr2mf2O1GLPzS2WAyw8R/Qb/r2nyn5im5YDzEXATfP2LE+u9eAlfMNbY1A2XVFhZtPMTC9dlszi7BpGDEBeHcf2kfxvTthJ+nVgcdFe260bQ/ig7AZ7c7rPiLYeKLRqqCjkTmT0Ydi/afs3W/+2gZb/98gE82ZFNRa6NPZ3+uHBDFxJQuRAScnx9wdUS060bTMRCBdW/C0ocABZe/YKQsaM9W/MmIGQZ/+OmsrXsRYdnOXF77cT8/7yvAw83EZcmRXD80htRuQS0ru6bNoRW9pn1QfBA+uwP2/xd6jDJcNUHdXC1Vy+LhC5c+AX0nGtb9WxOMr3nHzj6pdW+12flySw4vL9/LjiNldAn04v5L+nDNoG6E+LommkfjerSi17RtRGD9W7Dkr8b6Zc/BgBs6phV/Mhqz7ie9ZKRvcGC12fl4QzYvLd/LgYJKekX48c+rUpiY2gV3sx4a+nxHK3pN26Uk27Di9y2D2BGGFR8c7WqpXIPTur8cFt0G834FQ25DLn6Qr3eW8vSSnezLqyA5KpBXrhvAuPhOOtZd40Qrek3bQwQ2/ge+/QvYbUbI5ICbwKQtU2Iugj+sgu8ehtVzObR2Ea9X/g5zeH9e/e0A0uM76RwymhPQil7Ttig9DJ/fbbgnoi+CK/7V/uLiW5gD5YpH86+hojaCZzxe5WPPR5CE2zFdkHZ+ubQ0TUYrek3bQMQYsOPrP4O1Fi59Egb9Tlvx9aiqtfHS8j38+8d9uJkUd477NSGDbkH98DDq5xdh97cw6WWIajTCTnMeoxW9xvWU5sCX/wc7v4JuQ4yOxtZMI9wO+HbbEf62eBuHS6q5IrULD1zal86Bjhj4y58zfPeL74I30mHY3UamzvaSAkLT4mhFr3Eddjusn2f4m221MP4fMPhW40tXDQB5ZTU8vHgbX27JoU9nf567th9psSEnHthrDNy2yohOWvks7PzaeGB2HdD6QmvaHFrRa1xD7nbDF5/1P4gdaSTy0la8ExHhkw2HeOSLDKpqbdw3vje3jOhx6lBJr0DjK+G+Ew3r/rUxxvCGF//V2Kc5b9GKXtO6WKphxdPGgCCe/jDpFUi5Vnci1iO3tJo/f/wLy3fmMSA6mCd+nUyvCL+mFxCXDrevhh8eM9IgZ3xmvC0l/lq383mKznWjaR1EYNc3Rr74ov2QMhXGPQa+oa6WrE3x7bYjzPz4F6osNmZe0ofrh8acWzz8oQ3wxT2Qswl6jDZCVfWbU4dE57rRuJa8XUa+9b3fG/nWr//MSGOgcVJZa+XRLzJ4f00WiV0DeO6afmdmxZ+Mrv3hdz/A2jeML2tfGgJDboPhfwKvgHMvX9Mu0Ipe03JUFRsDYv/vFXD3hUvmwKAZYNbDztVnS3YJd3+wkf0FFdw6sif/l34BHm7NGFZqMsPgW4zInO8ehp+eg03vwugHjaRwuvO7w6NdN5rmx1IFa16Dlc8Yyr7/9TDmIfANc7VkbQoR4T+rD/DoF9sJ8/Pgn1enMrRnK7iyDq2Hb/5iDFAekQDjHjXSPWv/fbtGu240rYPNaliKy+dA2WHolW4o+MhkV0vW5qiosfKXT7fw2abDXNwngmeuTiHIp5WyS3YdYAxQnrHISPn8nykQPcyw8FtpCENN66IVvebcsVlg68eGm6ZgD0Slwa9fa7aRkToae3LLuPU/G9iXV85943vzh5E9Wz8BmVKQMBl6/8rIDrrin8YQhj1Gwei/QrdBrSuPpkXRil5z9liqjORjP70AJQcNN8C170PvS7Ub4CQs3nyYmR//go+Hmf/cPJgLe7nYneXmCYN/D/1+awzqsvJZeGOs4cq58C5D8evfst2jffSaM6eyEDbMh59fgopcw4If/idjzFOtFBrFbheeWrKTl5fvZWB0MP/6Tf9jKQzaEjXlsPY1WP0ylB+Fzklw4d2QMEl3ordxTuWj14pe03RyNhsf4GxZCNZqIy57xL2Gf1cr+JNSVm3hngWb+G57LlPTuvO3iQnNG1XTElhrjCRzq16E/F0Q2A0G3mQMwO4X4WrpNI2gFb3m7KmtgO2fG6/1Wf8Ddx/jS9ZBv4NO8a6Wrs1zoKCC3729jr15FTx0WTzXD41uX/ni7XYjK+bPc43B2E3u0GcCDLwRYkbo7KJtCB11ozkz7HY4sBI2vW98Pm+pgJAeRhx8ylTwDnK1hO2CVXvyue29DYjA2zelMczV/vizwWQy+lx6X2p8+Lb+Ldj8nhGxE9IDkq+BxCshrJerJdWcAm3RawzsdiO+evti2PYplGSBh7/hm039jZE+WFtvTead1Qd4ePE2YsN8eWP6QKJDGx/Mu11iqTYMgI3vQOZKQKBLP0i6yojkCejiagnPS7TrRtM41lo4+LPhmtnxBZTlgMnNiLRImWqE3nn4uFrKdoXdLjz+9XZeW7Gfi/tE8Py1qfh7deBOzNLDsPUT2PKRkU8HIDLVuHd6XwKdk3X/TSuhFb3GQAQK9sLeH4y8M/tXGG4ZN28jn3nfiUbkjHbNnBXVFht/+nAzX27J4fqh0cy+PAHz+TRAd/5uw2jY+TVkrwUEArpC3DjoMRJihuuvo1sQrejPV+x2yNthfOp+8H9wYJUR7w6Gf7XnxcbUYxR4dCDXggsoqqjld2+vY92BIh78VV9mDI9tX52uzU15ntGJu/Nr2LccasuN7REJEDvC+JguahD4d3KpmB0JrejPB0SgJBuObIEjv0D2OsheA9Ulxn7fCOg+2AiJ7HmxHnC7GTlYUMkN89aQXVTFM9ekcFmy9lE3wGaBw5tg/3+NyJ2Dq43wXIDA7hA1ALoONBR/pwTwbIasnechWtF3NKqKjVQD+bvh6NZjyr2qyHGAgvDe0G0wdB9izEN6aF9pC7Apq5ib31qL1S68dv3Axof50zTEWgOHNzqMkbVGEEBJlmOnguAYQ+FHxBshvBEJxv1r1kGCp0KHV7Y3RKAiD4qzjD9A8UEo2A35e4x5Rd6xY82eENHXSEHbORkiU4w/iLaKWpylGUe58/0NhPt78taNafQM123eJNw8DQOk+5Bj28qOGAr/6DbDeDmaYQwWL3Zjv8kNgrobCj+kp2Pew3gzDeiiXY+nQSv61kTEsLor8qA810gfUJ5nzMuOGkq9JNuYbDUNz/UJhdA4o7M0NA7C4ox5SKz+NN0FvP1zJg8v3kZS10Benz6IcH9PV4vUvvHvbHyI1WfCsW2WKsjbaSj/wr1GIEHhPqO/qbas4fleQUbHb0AXx+RY9osAnzBjJDOfMOOBcB6+2baKoldKXQI8D5iB10VkTmtct9mx1hpRKpYqqK00lmvKDT+4cyo+br3EcLVU5hsK3m49sVxlNm7IwCgjpW+fCcYn54FREOSYewe3dm01jWC3C098s4N//7iPsX0jeGFqP3w8tL3UIrh7Q5dUY6qPCFTkG0q/KBNKDxlhnqWHjeWczYbx1BhuXvUUfyh4hxgjbXkG1JsHHrceAB5+hjxuXu3yQdHid6hSygzMBdKBbGCtUmqxiGQ064Us1bBvmeH/s1nAVtvIZHHsr613jMWwnuuWLVVgqTymyOsr9caUdGN4+BkWhlegMQVGGS4Vv3CjU9QvAnzDHfMIQ4nrj5HaPNUWG3/6aDNf/pLDb4dE8/DE8yx8sq2glPFf8gs3Agwaw1pjfBdSkW9MlfXnBcfWC/dDTSlUl4Ld0rTru/s4lL63MXf3PratbjJ7Gm/aZg/H1NhyI9t8wyD6wuZrKwetYYqkAXtEZB+AUuoD4AqgeRV9TRm8f+3pjzO51WtYzxMb3N3L+NF8Qo/9gB6+jmVf4wMid8fk4djnFWTEnnsFGRaA7jTqcBRXGuGTazOLeODSPtwyosf5HT7Z1nHzNDp1g2OadryIEQlUU2Yo/ZoSx9zxELBUOqaqevP6U6WRF6oi31g+3sCsWz4dXQfC774/l5o3SmtopK5AVr31bKDBY1gpdQtwC0D37t3P7irewXDL8npPSI+GT0s3TyMhk7acNWdIVmEl0+etIbuwihen9uPyFB0+2eFQ6pg13lLZOUXAbmv8AVC3bG6ZUcbahOkpIq8Cr4IRXnlWhZjdjHwbGk0zsjmrmJvnr8ViE/4zY7AOn9ScPUoZesrsBrRuapHWUPSHgG711qMc2zSaNs13GUe58/2NhPp58MEtafSK0OGTmvZJa/gx1gJxSqlYpZQHcC2wuBWuq9GcNe+sPsAt76wjrpMfn942TCt5TbumxS16EbEqpe4AvsUIr3xTRLa19HU1mrPBbhee+HYH//7vPsb0ieDF3+jwSU37p1XuYBH5CviqNa6l0ZwtNVYb9370C59vPsx1Q7rz8OUJuJl1572m/aNNFY0GI3zylnfWs2Z/ITMv7cPvdfikpgOhFb3mvCer0Mg+mVVYxQtT+zFRh09qOhha0WvOa9ZmFnLrO+ux2Oy8c3Mag3uEulokjabZ0Ypec96ycH02f/lkC12DvXlj+kB66OyTmg6KVvSa8w6bXXjSEVkzrFcoL/1mAIE+OgOopuPSLhS9xWIhOzub6upqV4uiaefYRSiqqGVgoJ1RV0UR6O3O4QN7OOxqwTQdHi8vL6KionB3b32jol0o+uzsbPz9/YmJidGREJqzptZqI7OgksAAO32CvAjz0znkNa2DiFBQUEB2djaxsa0/jGe7CBKurq4mNDRUK3nNWVNWbWF3bjkWm52YMB+t5DWtilKK0NBQl3kl2oVFD2glrzkrRITcshqOllbj5W4mOtQHTzezq8XSnIe4Uoe1G0Wv0ZwpVrud7MIqSqstBPl4EBXkjUkPFKI5D2kXrhtXk5mZibe3N6mpqa1yveLiYl566aUmHRsTE0N+fn6Ty8rMzCQxMRGAdevWcddddwHw8MMP8/TTT5/R9S68sPlHwmlMzvo89NBDfPfdd6c9v6rWxt7ccsqqrXQJ8qZbsDfff/8dAwYMICkpiQEDBvDDDz84j4+JiSEpKYmkpCTi4+P561//ekav2SeTF2DGjBlkZJz5ODubNm3iq6/OLHNIZmYm77333kn3z58/n7i4OOLi4pg/f/4py9q5cyepqanOKSAggOeeew6AHTt2kJqaSr9+/di7dy8vvPACffv2Zdq0aZSUlHD55ZeTkpJCQkIC8+bNc5Z58OBBxo0bR9++fYmPjyczMxM4/X18fB1P1tY//PAD/fv3JzExkenTp2O1nn5UuKlTp5KcnMyzzz5LYWEh6enpxMXFkZ6eTlFRUZNk2rt3L6mpqfj5tdEQXRFpU9OAAQPkeDIyMk7Y1prs379fEhISTntcTU2NlJeXt9r1RESio6MlLy+vyWWdrOzZs2fLU089dc7Xay7OpA3qY7fbJa+sWn7JLpaMwyVSXm1x7tuwYYMcOnRIRES2bNkiXbp0ce6rX6+ysjKZOnWqXH/99S0u76mYN2+e3H777Wd0zrJly2TChAmN7isoKJDY2FgpKCiQwsJCiY2NlcLCwiaVa7VapVOnTpKZmSkiIo8//rg8+uijzv29e/eWrKwsERF57LHH5M9//rOIiOTm5kpwcLDU1NSIiMjIkSNlyZIlImK0c0VFhYic2X11sra22WwSFRUlO3fuFBGRWbNmyeuvv37KsnJycqRnz57O9fvuu08ef/xxZx3r6lFcXCw2m+20svn6+p5yf0vqMmCdnESvaou+Gdi+fTt/+tOf6N27N7t27QIMC+WBBx4gNTWVgQMHsmHDBsaPH0/Pnj155ZVXACgvL2fMmDH079+fpKQkPvvsMwBmzpzptBDuu+8+li9fzogRI5gwYQK9e/fm1ltvxW63nyDHM888Q2JiIomJiU7L6/iy6rN8+XIuu+wy5/rmzZsZOnQocXFxvPbaa6etd531snz5ckaNGsWVV15Jnz59mDZtGsZ9B+vXr2fkyJEMGDCA8ePHk5OTA8ALL7xAfHw8ycnJXHttE4aAdHDDDTewcOFCZxvPnj3b2X5bt2VwoKCSPYfzefS+O7l+4lguGjLI2a79+vWjSxcjvUFCQgJVVVXU1NQ0Wq9XXnmFRYsWUVhYeML+xtoZwGq1Mm3aNPr27cuVV15JZWUlAKNGjWLdunUALFmyhKFDh9K/f3+uuuoqysvLAVi7di0XXnghKSkppKWlUVJSwkMPPcSCBQtITU1lwYIFDWTIzMxk+PDh9O/fn/79+7Nq1SrA+L1XrFhBamoqzz77bINzvv32W9LT0wkJCSE4OJj09HS++eYbDhw4QFxcHPn5+djtdoYPH86SJUsanPv999/Ts2dPoqOj+eqrr3juued4+eWXGT16NLfeeiv79u3j0ksv5dlnn0UpRVlZGSJCeXk5ISEhuLm5kZGRgdVqJT093dnOPj7HBuB48sknSUpKIi0tjT179gBw9OhRJk+eTEpKCikpKc56NtbWBQUFeHh4cMEFFwCQnp7Oxx9/DMCaNWsYOnQo/fr148ILL2Tnzp0AjBs3jkOHDpGamsqKFSv47LPPmD59OgDTp09n0aJFAKxcuZLevXvz8MMPc/DgwRPuiTbPyZ4ArppOZ9E/vHirXP3KqmadHl689ZRPysYsiPLycnnzzTdl2LBhMmzYMHn99deltLTUuT86OlpeeuklERH54x//KElJSVJaWiq5ubkSEREhIiIWi0VKSkpERCQvL0969uwpdrv9hOstW7ZMPD09Ze/evWK1WmXs2LHy0UcfOa+Tl5cn69atk8TERCkvL5eysjKJj4+XDRs2nNKir2/9zZ49W5KTk6WyslLy8vIkKirKaf3Wp77lVWe9LFu2TAICAiQrK0tsNpsMGTJEVqxYIbW1tTJ06FDJzc0VEZEPPvhAbrzxRhERiYyMlOrqahERKSoqalKbi4hMnz69Qd1feOEFERF55rkX5NdTfyu/ZBfL3X+6T95++21n2XFxcSe8aX300UcyZsyYRutVR0pKiqxevbrBtlO1MyArV64UEZEbb7zR+YY0cuRIWbt2reTl5cnw4cOdssyZM0f+9re/SU1NjcTGxsqaNWtERKSkpEQsFsspLfqKigqpqqoSEZFdu3ZJ3f/mVBb9U0891cAKf+SRR5wyvvbaa3LllVfKk08+KbfccssJ5954443y4osvOtePfwOs336lpaUyatQo6dy5s/j6+soXX3whIiKffvqpTJgwQSZPniypqaly7733itVqdZ7/97//XURE5s+f76zD1VdfLc8++6yIGG8VxcXFJ21ru90u3bt3l7Vr14qIyF133SWJiYkN2lREZOnSpTJlyhQROfE+CwwMdC7b7fYG63l5efLMM89ISkqKjB8/Xj788EPnm0od2qLvYERGRvLGG2/w+uuvs3LlSm6++Wb8/f0bHDNx4kQAkpKSGDx4MP7+/oSHh+Pp6UlxcTEiwl/+8heSk5MZO3Yshw4d4ujRo41eLy0tjR49emA2m5k6dSorV65ssH/lypVMnjwZX19f/Pz8mDJlCitWrDijOl1xxRV4e3sTFhbG6NGjWbNmTZPPTUtLIyoqCpPJRGpqKpmZmezcuZOtW7eSnp5Oamoqf//738nOzgYgOTmZadOm8Z///Ac3t7OPCZg0aTI5xVWE9+jL4ewseoX7snL5DzzxxBOkpqYyatQoqqurG1hh27Zt4/777+ff//73KcsWOXFUy1O1c7du3Rg2bBgA11133Qm/0erVq8nIyGDYsGGkpqYyf/58Dhw4wM6dO4mMjGTQoEEABAQEnLZNLBYLv/vd70hKSuKqq646qz6A+syYMYPS0lJeeeWVE/pqamtrWbx4MVdddVWTyvr2229JTU3l8OHDbNq0iTvuuIPS0lKsVisrVqzg6aefZu3atezbt4+33nrLed7UqVOd859//hkwfO5/+MMfADCbzQQGBgKNt7VSig8++IB77rmHtLQ0/P39MZuNCKuSkhKuuuoqEhMTueeee9i27fRDYiilGkTKhIWFcc8997Bp0yZmz57NQw89xMCBA5vUJq6m3UXdzL48wdUiALBw4ULeeOMNpkyZwrXXXsv06dOJjo5ucIynpxGrbTKZnMt161arlXfffZe8vDzWr1+Pu7s7MTExJ+0APD40qyVCtc7lGvXrZzabsVqtiAgJCQnOP219vvzyS3788Uc+//xzHnvsMbZs2XLGCl8EDpVa8VE1BPt64W4SvD3cEBE+/vhjevfufcI52dnZTJ48mbfffpuePXuetOyysjIyMzOdboCmcLr2ExHS09N5//33G2zfsmVLk69Rx7PPPkunTp3YvHkzdrsdLy+v057TtWtXli9f7lzPzs5m1KhRAFRWVjofwuXl5Q2Mlq+//pr+/fvTqVOnJsk2b948Zs6ciVKKXr16ERsby44dO4iKiiI1NZUePXoAMGnSJFavXs3NN98MNGyv0917J2vroUOHOh+8S5YscbpSZ82axejRo/n000/JzMx01vt4OnXqRE5ODpGRkeTk5BAR0XCg8IyMDObNm8eiRYsYOXIkv/vd75rUJq5GW/Rnybhx41iwYAErVqwgMDCQK664grFjxzqjCJpCSUkJERERuLu7s2zZMg4cOACAv78/ZWVlDY5ds2YN+/fvx263s2DBAi666KIG+4cPH86iRYuorKykoqKCTz/9lOHDhzda1sn47LPPqK6upqCggOXLlzstzLOld+/e5OXlORW9xWJh27Zt2O12srKyGD16NE888QQlJSVOX3VTsNuFnJIqrHY7dhFiw3zpFOBF3V9//PjxvPjii06LfOPGjYARgTRhwgTmzJnjtAYbo7y8nNtuu41JkyYRHBzcYN/J2hmMiJK6ur733nsn/EZDhgzhp59+cvqfKyoq2LVrF7179yYnJ4e1a9cCxkPGarWe8rcrKSkhMjISk8nEO++8g81mAxq/d+oYP348S5YsoaioiKKiIpYsWcL48eMBuP/++5k2bRqPPPLICcrr/fffd1rbTaF79+58//33gOFj37lzJz169GDQoEEUFxeTl5cHGNZ6fHy887y6fogFCxYwdOhQAMaMGcPLL78MgM1mo6SkBDh5W+fm5gJQU1PDE088wa233upsr65duwI0eIs4nokTJzqjkebPn88VV1wBwIYNGxgyZAgzZsygT58+bNy4kddff53Bgwc3uV1ciVb050hoaCh33303mzZt4h//+IfzVbEpTJs2jXXr1pGUlMTbb79Nnz59nGUOGzaMxMREZwfqoEGDuOOOO+jbty+xsbFMnjy5QVn9+/fnhhtuIC0tjcGDBzNjxgz69evXaFknIzk5mdGjRzNkyBBmzZrl7Lg827BSDw8PFi5cyP33309KSgqpqamsWrUKm83GddddR1JSEv369eOuu+4iKCiIdevWMWPGDOf5O3fuJCoqyjl99NFHWGx2ckqrySurwaQUPSN88fdqmDtk1qxZWCwWkpOTSUhIYNasWQD861//Ys+ePTzyyCPOkME6xQAwevRoEhMTSUtLo3v37o26dk7WzmA82ObOnUvfvn0pKipyuhzAsDjDw8N56623nOF8Q4cOZceOHXh4eLBgwQLuvPNOUlJSSE9Pp7q6mtGjR5ORkdFoZ+xtt93G/PnzSUlJYceOHfj6+jp/Q7PZTEpKygmdsSEhIcyaNYtBgwYxaNAgHnroIUJCQvjvf//L2rVrncrew8PDGRJZUVHB0qVLmTJlSpN/91mzZrFq1SqSkpIYM2YMTzzxBGFhYZjNZp5++mnGjBlDUlISItLgoVJUVERycjLPP/+8U/bnn3+eZcuWOUNi61xUJ2vrp556ir59+5KcnMzll1/OxRdfDMCf//xnHnjgAfr163fKkMuZM2eydOlS4uLi+O6775g5cyYA3t7ezJs3j1WrVnHzzTe33TDKk6Aa80O6koEDB0pdhEId27dvp2/fvi6SyIhwuOyyy9i6datLrr98+XKefvppvvjiC5dcvy1gsdnJKa6iuMqCp5uJLkHeJyj4tkpSUhKLFy92SY4TTevi5+d3yrfTltRlSqn1ItJop4G26JuA2WympKSk1T6Y0hzDLkJ+WQ27jpRRUm2lU4AXcRH+7UbJp6enk5SUpJV8B6cuhLmp/RitjbboNW0SEaG02sqRkmpqrDb8PN3oGuSNp7vOU6Npv7jKom93UTeajk9ljZWckmoqaq14upmJCfXF38tNJ7bTaM4Sreg1bYaqWitHS2sorbbgZjLRNcibEF8PreA1mnNEK3qNy6mstZLrUPBmk6JTgDEoiFlnmtRomgWt6DUuQUQor7GSX15LWQMF74HZpGMENJrmRP+jmoBOU9z49c4mTbHdLhRU1LD7aDn78yuostjoHOBFn87+dArwcir5c01T3BhLly7VaYp1muImXa+mpoZrrrmGXr16MXjw4CZ/CFlVVUVqaioeHh5Nrk+rcLIkOK6adJrijpmmuLLWKoeKKmXboWLZnFUku46USmF5jdjs9ibJ3RzoNMU6TXEdp7ve3Llz5fe//72IiLz//vty9dVXi4iRzLC2tva0Mp6sfJ3UrB2j0xQ3nqbYZrfz/YqfSbvwIgYMGMBVky6joiifHuF+fPXBmwwblEpqSkqzpSnesWMHYHzNedNNN5GWlka/fv10mmIH53Oa4oKCAsaNG0dCQgIzZsxokLDu7bffJjk5mZSUFH77298CNEhXfOWVV/L9998jIuzatYsLLriAe++9l+3bt59wb7RZTvYEcNV0Wov+q/tF3vxV805f3X/KJ6VOU3yM06UprrVYZGDaYPnw8yWyfn+epAwYJD9v3Sd5pdXy7nvvtVia4rlz58rNN98sIiIPPPCAvPPOO86ydZpig/M5TfGdd94pf/vb30RE5IsvvhBA8vLyZOvWrRIXF+eUvaCgQEREEhISnG8oIiI9evRoUL/XXntNLrzwQhk2bJi8+eabJ9xf2qLvIOg0xcew2uz0GzAQq1cwO45WEHtBPPsyMyk+nMm+XTu4ddpkxg4fzOP/+Eezpymuy8EyYMAApx91yZIlzJkzR6cpPgM6epriH3/8keuuuw6ACRMmOJPV/fDDD1x11VWEhYUBRj6g0+Hv78+MGTP46aefeO2113jttdeIjIxsUtu4ivYXdXPpHFdLAJzfaYpFhIoaKwLsPlrGgcJK7CY3qiw2Qn09CPbzIsLXjXB/zxZNUwzH2rguNXKdfDpN8Ymcz2mKz5SuXbuSlZVFVFQUVquVkpISQkNDnfszMzOZP38+77//PikpKTz88MNndZ3WQlv0Z8n5lKbYbjdCIXNLq7HahR1HytibV44ImJQixMcDXw83+nT2p0uQN+5mE0qpFktTfDp0mmKdpvj4NMUjRoxwRiN9/fXXzkG/L774Yj766CMKCgoAnH0y9dMVL1y4kIsvvhilFJmZmYwdO5ZJkyYRFBTETz/9xIIFCxg3blyT28cVaEV/jnTENMWDhwzh//78APgEsze3nPikZPbllXOktBoEgrzd6R7ig0lBzwg/gn09MJvUCVZWS6Qpbgo6TbFOU3x8muLZs2fz448/kpCQwCeffEL37t0Bo1P+wQcfZOTIkaSkpPB///d/ANx8880UFBTQq1cvnnnmGebMMTwJZrOZf/zjH2zatIm77767gZXfltFJzZpAR0xTLCJY7UKNxUa11U6N1U51rY0qiw27454wKYWXuxlfDzO+nm74eJhxM2vb4EzRaYrPP2JiYli3bp3T91+HTmrWhqmfpnjTpk2uFqfJiAgWm2Cx2am12am1GlON1U6N1YbNfuwhb1YKT3czIb4eeLmb8fEw4+lm0nlmzhGdpvj8oqqqiqFDh2KxWDC1oS+8tUXfDhER7A4lbrUJVrvdWLbbsToUu6Hc5YTIETeTCU93E15uJjzdDWXu5WbGzXyi60Wj0TQvHdKiV0pdBTwM9AXSRGTdqc84OSLSYRSRoaiNQTXsdkNp163b7A0na93ycfvsjTyglVK4mxRuZhPe7mYCvE14mE14uJlwNxvLJp0oTKNxCa40qlvadbMVmAKcOmD5NHh5eVFQUEBoaOgpQ/4MT4QgAuLc3vg2cazVtb2IHLf/2HkAdjl2DakrT4y5nXrLcuxaDRS6CHb7seWmYFIKs+nY5GE2YXZXuDmUuZv5mGJ3cxzTUR6GGk1HQkQoKChoUhhsS9Ciil5EtsO5x3xHRUWRnZ3tDMtqDJtdyClpehKq5kABdVVTSh23Dopj25RSKGUo7/rbTHXH1Vs31W13FGZzTBqNpv3i5eVFVFSUS67dJjpjlVK3ALcAzrCn+ri7u5+2M6vaYuOnVZlO69fNpDDVzZXCzeyYm0xNOKahJV1nTXu6GW4QTzczHm4mnS9do9G0C85Z0SulvgM6N7LrQRH5rClliMirwKtgdMaejRxe7mZ+P/LkXzpqNBrN+co5K3oRGdscgmg0Go2mZWg7gZ4ajUajaRFaNI5eKTUZeBEIB4qBTSIy/jTn5AEHzuGyYUAbGtrlrOko9QBdl7ZKR6lLR6kHnFtdokUkvLEdbe6DqXNFKbXuZB8NtCc6Sj1A16Wt0lHq0lHqAS1XF+260Wg0mg6OVvQajUbTwemIiv5VVwvQTHSUeoCuS1ulo9Slo9QDWqguHc5Hr9FoNJqGdESLXqPRaDT10Ipeo9FoOjgdTtErpR5VSv2ilNqklFqilOriapnOFqXUU0qpHY76fKqUCnK1TGeLUuoqpdQ2pZRdKdXuQuGUUpcopXYqpfYopWa6Wp5zQSn1plIqVynlmiHTmgmlVDel1DKlVIbj3rrb1TKdLUopL6XUGqXUZkdd/tas5Xc0H71SKkBESh3LdwHxInKri8U6K5RS44AfRMSqlHoCQETud7FYZ4VSqi9GRud/A/eey9gErY1SygzsAtKBbGAtMFVEMlwq2FmilBoBlANvi0iiq+U5W5RSkUCkiGxQSvkD64FJ7fF3UUaqWl8RKVdKuQMrgbtFZHVzlN/hLPo6Je/Al2Np6NsdIrJERKyO1dWAa3KcNgMisl1EdrpajrMkDdgjIvtEpBb4ALjCxTKdNSLyI1DoajnOFRHJEZENjuUyYDvQ1bVSnR1iUO5YdXdMzaa7OpyiB1BKPaaUygKmAQ+5Wp5m4ibga1cLcZ7SFciqt55NO1UoHRWlVAzQD/ifi0U5a5RSZqXUJiAXWCoizVaXdqnolVLfKaW2NjJdASAiD4pIN+Bd4A7XSntqTlcXxzEPAlaM+rRZmlIXjaa5UUr5AR8Dfzzujb5dISI2EUnFeHNPU0o1m1utTQw8cqacQWrkd4GvgNktKM45cbq6KKVuAC4Dxkgb71DpwCmrDwHd6q1HObZpXIzDn/0x8K6IfOJqeZoDESlWSi0DLsEYjvWcaZcW/alQSsXVW70C2OEqWc4VpdQlwJ+BiSJS6Wp5zmPWAnFKqVillAdwLbDYxTKd9zg6MN8AtovIM66W51xQSoXXRdUppbwxOv6bTXd1xKibj4HeGBEeB4BbRaRdWl9KqT2AJ1Dg2LS6HUcQnXHK6raEUupXwHOAGXhTRB5zrURnj1LqfWAURkrco8BsEXnDpUKdBUqpi4AVwBaM/zvAX0TkK9dJdXYopZKB+Rj3lwn4UEQeabbyO5qi12g0Gk1DOpzrRqPRaDQN0Ypeo9FoOjha0Ws0Gk0Hp82FV4aFhUlMTIyrxdBoNJp2xfr16/NPNmZsm1P0MTExrFvXbtKgaDQaTZtAKXXgZPu060aj0Wg6OG3OotdoNJrzBRGhrMZKXlkNeWU1mJQiLTak2a+jFb1Go9G0AFW1No6UVpNTXEVOSbWxXFJFbmkNeeU1TuVeY7U7z0npFsRntw9rdlm0otdoNJozxG4X8sprOFhYycGCSnJKqjhcUs2RkmpySgyFXlxpOeG8IB93Ovl7Ee7vSUyML+H+noT7eRIRYMw7B3q1iLxa0Ws0Gk0jVNZanYr8YGElWYXG/GBhJVlFVdTWs8QBQnw9iAz0omuQFwOig4gM9CYy0IvOgV7OZS93s0vqohW9RqM5bxERjpRWsze3gr155ezLK2dvXgX78so5XFLd4Fh/Tze6h/oQF+HPmL6d6BbiQ/cQH7oFe9MlyNtlSrwpaEWv0Wg6PCJCTkk1O46Usj2njF1HyxyKvYLKWpvzOD9PN3qG+zK4Ryg9w32JDvUlOtRQ6IHe7hgJM9sfWtFrNJoORWWtlZ1HythxpIwdOaVsd8xLq63OY7oGedMzwo9BMSH0CPejZ7gvvcL9CPf3bLfK/FRoRa/RaNot1RYb23NK+SW7xDEVsyevnLqkvL4eZvpEBnB5Shf6dPanT2QAvTv7E+Dl7lrBWxmt6DUaTbvAZhd2HS1j48FithwqZnNWCbuOlmG1G1o9zM+TlKhAfpUUSUKXAPpGBtA1yBuTqeNZ6GeKVvQajaZNUllrZdPBYtYdKGLdgSI2HiiirMZwvwR6u5McFcjv+/QgqWsQKd0C6Rzg1SHdLs2BVvQajaZNUFxZy+p9BfxvfyHrMovIyCnFZheUggsi/Lk8tQsDo4MZEB1M9xAfrdTPAK3oNRqNS6iosbIms5BVe/JZtbeAjJxSRMDL3URqtyD+MLInA2KC6d89mEDv88un3txoRa/RaFoFi83OhgNF/LQnn5/2FrA5qxirXfAwm+gfHcQ9Yy/gwp6hJEcF4eGm8y02J1rRazSaFiO3tJrlu/JYvjOXFbvyKauxYlKQFBXELSN6cGHPMAZEB+Pt0XY/NuoIaEWv0WiaDavNzqasYpbvzGPZzly2HS4FIMLfk18lRTK6TzhDe4ZpV0wroxW9RqM5J6otNlbszufbbUf4fvtRiiotmE2KAd2DuW98b0b3jqBvpL/uPHUhWtFrNJozprTawrIduXy77QjLd+ZRWWvD38uNMX0iGNO3EyPiwgn00VZ7W0Ereo1G0ySKKmr5eusRvtl2hJ/35mOxCeH+nkzu15XxCZ0Z0iNUd6K2UZqk6JVSlwDPA2bgdRGZc9z+Z4HRjlUfIEJEghz7bMAWx76DIjKxGeTWaDStQHmNlaUZR1i86TArdudjtQvdQ3y4cVgs4xM60a9bsP7ytB1wWkWvlDIDc4F0IBtYq5RaLCIZdceIyD31jr8T6FeviCoRSW02iTUaTYtSbbGxfGcen28+zPc7jlJtsdMl0IubL4rl8pQuJHQJ0P72dkZTLPo0YI+I7ANQSn0AXAFknOT4qcDs5hFPo9G0Bna7sCazkI/XZ/PNtiOUVVsJ9fXgqgHdmJjahQHdteXenmmKou8KZNVbzwYGN3agUioaiAV+qLfZSym1DrACc0Rk0dmJqtFompuswko+2XCIhRuyyCqsws/TjfEJnZmY2oVhPUNxM2ufe0eguTtjrwUWioit3rZoETmklOoB/KCU2iIie+ufpJS6BbgFoHv37s0skkajqU9VrY2vt+awcH02q/YWoBRc2DOUP6X3ZnxCZ/3xUgekKYr+ENCt3nqUY1tjXAvcXn+DiBxyzPcppZZj+O/3HnfMq8CrAAMHDpSmCK7RaJqOiLA5u4T3/3eQL7fkUF5jpXuID/+XfgFT+nclKtjH1SJqWpCmKPq1QJxSKhZDwV8L/Ob4g5RSfYBg4Od624KBShGpUUqFAcOAJ5tDcI1Gc3rKa6x8tukQ7/3vINsOl+LjYeZXSZFcOSCKtJgQ7Xc/TzitohcRq1LqDuBbjPDKN0Vkm1LqEWCdiCx2HHot8IGI1LfI+wL/VkrZAROGj/5knbgajaaZ2Ha4hPf+d5BFGw9RUWujT2d/Hp2UyKTULvifZ6MraUA11MuuZ+DAgbJu3TpXi6HRtDuqam188cth3v3fQTZlFePpZuKy5C5MG9Kdft2CdEhkB0cptV5EBja2T38Zq9G0cw4VV/H2z5l8sCaLkioLPcN9eeiyeH7dP0qnIdAAWtFrNO0SEWHdgSLm/bSfb7cdRUQYn9CZ6RfGMDg2RFvvmgZoRa/RtCNqrDY+35zDW6v2s/VQKYHe7swYHsv1Q2PoGuTtavE0bZTzStFbLBays7Oprq52tSgazRlhswsVNVYqaq0E2uHeND/8PIPw9jBjUlCak0lpjqul1LQGXl5eREVF4e7edLfceaXos7Oz8ff3JyYmRr/aatoF1RYbeWU1FFdZ8Bahk5c7oX4e+Hm66Xv4PEREKCgoIDs7m9jY2Cafd14p+urqaq3kNW0eEaGi1kZ+WQ2l1RZMShHi60GYrwee7vqr1fMZpRShoaHk5eWd0XnnlaIHtJLXtFlEhNIqC3nltVTWWnEzmegU4EWor4fOOaNxcjY67LxT9BpNW8NuF4oqa8kvr6HGasfDzUTXIG+CfTz0l6uaZkGbCa1IZmYm3t7epKamtsr1iouLeemll5p0bExMDPn5+U0uKzMzk8TERADWrVvHXXfdBcDDDz/M008/fUbXu/DCC5sk49lQX876PPTQQ3z33XdnVebSpUsZMGAASUlJDBgwgB9+OJasNSYmhqSkJJKSkoiPj+evf/3rSTv/rTY7R0ur2XGkjEPFVZhNCspyuXLshYT6eZ6g5GfMmEFGxpl/WL5p0ya++uqrMzonMzOT995776T758+fT1xcHHFxccyfP/+UZe3cuZPU1FTnFBAQwHPPPQfAjh07SE1NpV+/fuzdu5cXXniBvn37Mm3aNEpKSrj88stJSUkhISGBefPmOcs8ePAg48aNo2/fvsTHx5OZmQmc/j4+nueff57ExEQSEhKcMjXWFvXvoccff5xevXrRu3dvvv322wbH2mw2+vXrx2WXXebctn//fgYPHkyvXr245pprqK2tbZJsK1asID4+vtH794wRkTY1DRgwQFqKjIyMFiu7Kezfv18SEhJOe1xNTY2Ul5e32vVERKKjoyUvL6/JZZ2s7NmzZ8tTTz11ztdrLs6kDZrKhg0b5NChQyIismXLFunSpYtzX/16lZWVydSpU+X6669vcH6t1SaHiiplS3axbM4qkn155VJWbRG73d4i8s6bN09uv/32Mzpn2bJlMmHChEb3FRQUSGxsrBQUFEhhYaHExsZKYWFhk8q1Wq3SqVMnyczMFBGRxx9/XB599FHn/t69e0tWVpaIiDz22GPy5z//WUREcnNzJTg4WGpqakREZOTIkbJkyRIRMdq5oqJCRM7svtqyZYskJCRIRUWFWCwWGTNmjOzevfuE4+r/Jtu2bZPk5GSprq6Wffv2SY8ePcRqtTqP/ec//ylTp05t0HZXXXWVvP/++yIi8vvf/15eeuklEZEmtdnJ7ofGdBlGSppG9ep5a9H/7fNtXPPvn5t1+tvn285Jpu3bt/OnP/2J3r17s2vXLsCwUB544AFSU1MZOHAgGzZsYPz48fTs2ZNXXnkFgPLycsaMGUP//v1JSkris88+A2DmzJns3buX1NRU7rvvPpYvX86IESOYMGECvXv35tZbb8Vut58gxzPPPENiYiKJiYlOK+f4suqzfPnyBhbM5s2bGTp0KHFxcbz22munrbefn5+znFGjRnHllVfSp08fpk2bhjhSdKxfv56RI0cyYMAAxo8fT06OEUv4wgsvEB8fT3JyMtdee22T2/qGG25g4cKFzjaePXu2s/127NgBQEVFBTfddBNpaWn069fP2a79+vWjS5cuACQkJFBVVUVNTU2j9XrllVdYtGgRhYWF1FptHCqqZMeRMgrKa/lw3stMHX8Rl48azOsv/8vpe7VarUybNo2+ffty5ZVXUllZCcCoUaOoSw+yZMkShg4dSv/+/bnqqqsoLy8HYO3atVx44YWkpKSQlpZGSUkJDz30EAsWLCA1NZUFCxY0kDEzM5Phw4fTv39/+vfvz6pVqwDj916xYgWpqak8++yzDc759ttvSU9PJyQkhODgYNLT0/nmm284cOAAcXFx5OfnY7fbGT58OEuWLGlw7vfff0/Pnj2Jjo7mq6++4rnnnuPll19m9OjR3Hrrrezbt49LL72UZ599FqUUZWVliAjl5eWEhITg5uZGRkYGVquV9PR0Zzv7+BzLvvnkk0+SlJREWloae/bsAeDo0aNMnjyZlJQUUlJSWLVqFdu3b2fw4MH4+Pjg5ubGyJEj+eSTTwDjfqs7du7cuc6yP/vsM6699lo8PT2JjY2lV69erFmzBjCi+r788ktmzJjhPF5E+OGHH7jyyisBmD59OosWLQJgwYIFJCYm8s9//vOMO1fPFO2jdzEVFRV8+OGHvPHGGwDceOONPPzww/j7+zuP6d69O5s2beKee+7hhhtu4KeffqK6uprExERuvfVWvLy8+PTTTwkICCA/P58hQ4YwceJE5syZw9atW9m0aRNgKNI1a9aQkZFBdHQ0l1xyCZ988onzJgTjBp83bx7/+9//EBEGDx7MyJEjTyir7lW5MX755RdWr15NRUUF/fr1Y8KECU7FeDo2btzItm3b6NKlC8OGDeOnn35i8ODB3HnnnXz22WeEh4ezYMECHnzwQd58803mzJnD/v378fT0pLi4+Izavj5hYWFs2LCBl156iaeffprXX3+dxx57jIsvvpg333yT4uJi0tLSGDt2LL6+vs7zPv74Y/r374+np2ej5QYEBBATE8vKdVuIjU8FBcE+7mTt2sqnC95lzZqG7RwcHMzOnTt54403GDZsGDfddBMvvfQS9957r7PM/Px8/v73v/Pdd9/h6+vLE088wTPPPMPMmTO55pprWLBgAYMGDaK0tBQfHx8eeeQR1q1bx7/+9a8T5IuIiGDp0qV4eXmxe/dupk6dyrp165gzZw5PP/00X3zxxQnnHDp0iG7djmUuj4qK4tChQ0RHR3P//ffzhz/8gbS0NOLj4xk3blyDcz/44AOmTp0KwK9+9StuvfVW/Pz8nPX75ptvWLZsGWFhYZSVlTFx4kS6dOlCWVkZCxYswGQysWvXLoKCgpgyZQr79+9n7NixzJkzB7PZiEgKDAxky5YtvP322/zxj3/kiy++4K677mLkyJF8+umn2Gw2ysvLCQ4O5sEHH6SgoABvb2+++uorBg40UsXceOON/Otf/2LEiBENDJtDhw4xZMiQE+oO8Mc//pEnn3ySsrIy5/6CggKCgoJwc3M74fhbb72VCRMm8NZbbzFixAgSEhKYMWMG48aNw2RqXhv8vFX0sy9PcLUIAERGRpKcnMzrr79Onz59Gj1m4kRjPPWkpCTKy8vx9/fH39/fqdx8fX35y1/+wo8//ojJZOLQoUMcPXq00bLS0tLo0aMHAFOnTmXlypUNFP3KlSuZPHmyU5lNmTKFFStWOGVoCldccQXe3t54e3szevRo1qxZw6RJk5p0blpaGlFRUQCkpqaSmZlJUFAQW7dudVpwNpuNyMhIAJKTk5k2bRqTJk1q8jUaY8qUKQAMGDDAadUtWbKExYsXO/scqqurOXjwIH379gVg27Zt3H///SdYrXVU1drILaum2mKlvMZKqJ8HYX6eeLiZ+Hj1zydt527dujFs2DAArrvuOl544YUGin716tVkZGQ4j6mtrWXo0KHs3LmTyMhIBg0aBBgPmdNhsVi444472LRpE2az2fkmebbMmDGDjz76iFdeecVpFNRRW1vL4sWLefzxx5tU1rfffktqaio//PADe/fuJT09neHDh2O1WlmxYgUbN26ke/fuXHPNNbz11lvcfPPNAM4HydSpU7nnHmM46x9++IG3334bALPZTGBgIIGBgdx///2MGzcOX19fUlNTMZvNFBcXU1xczIgRIwD47W9/y9dff31KWb/44gsiIiIYMGAAy5cvb2pz0a1bN2bNmsVf//pXvv76a2666SYGDhzI4sWLT3/yGXDeKvq2wsKFC3njjTeYMmUK1157LdOnTyc6OrrBMXXWoslkamA5mkwmrFYr7777Lnl5eaxfvx53d3diYmJO2gF4fGhWS4Sbnss16tfPbDZjtVoRERISEvj5559POP7LL7/kxx9/5PPPP+exxx5jy5YtTuvpTKi7bt01wXjt/vjjj+ndu/cJx2dnZzN58mTefvttevbs2WBfZY2VzPwKSqstVFeUk3Moi7FDU4loYoqC07WfiJCens7777/fYPuWLVuaVH59nn32WTp16sTmzZux2+14eXmd9pyuXbs2UGbZ2dmMGjUKgMrKSrKzswGcRkkdX3/9Nf3796dTp05Nkm3evHnMnDkTpRS9evUiNjaWHTt2EBUVRWpqqtNgmTRpEqtXr3Yq+vrtdbp77+abb3ae95e//MVpZJyq7llZx0ZWzc7OpmvXrixevJjFixfz1VdfUV1dTWlpKddddx3vvPMOxcXFWK1W3NzcnMfXZ82aNcybN4+lS5dy9dVX87vf/a5J7XMmnLc++rbCuHHjWLBgAStWrCAwMJArrriCsWPHntI1cjwlJSVERETg7u7OsmXLOHDgAAD+/v4NXiPBuKn279+P3W5nwYIFXHTRRQ32Dx8+nEWLFlFZWUlFRQWffvopw4cPb7Ssk/HZZ59RXV1NQUEBy5cvd1qYZ0vv3r3Jy8tzKnqLxcK2bduw2+1kZWUxevRonnjiCUpKSpy+6uZg/PjxvPjii85+go0bNwJGBNKECROYM2eO06oWEcqrrVjtwv6CCipqrfiZrDz/6EwmT5pERFhog7JP1s5gRJTU1fW999474TcaMmQIP/30k9P/XFFRwa5du+jduzc5OTmsXbsWgLKyMqxW6yl/u5KSEiIjIzGZTLzzzjvYbMYooKc6Z/z48SxZsoSioiKKiopYsmQJ48ePB+D+++9n2rRpPPLIIycorPfff99pbTeF7t278/333wOGj33nzp306NGDQYMGUVxc7PRr//DDD8THxzvPq+uHWLBgAUOHDgVgzJgxvPzyy4DxRlhSUgJAbm4uYLT5J598wm9+8xuCgoIICgpi5cqVALz77rvOsidOnMgHH3xATU0N+/fvZ/fu3aSlpfH444+TnZ1NZmYmH3zwARdffDH/+c9/UEoxevRoZ3/Q/PnzueKKKwDjjTE5OZm//vWvjB49moyMDJ577jkSEprf26AVfRshNDSUu+++m02bNvGPf/zD6W9sCtOmTWPdunUkJSXx9ttvO11AoaGhDBs2jMTERKefcdCgQdxxxx307duX2NhYJk+e3KCs/v37c8MNN5CWlsbgwYOZMWMG/fr1a7Ssk5GcnMzo0aMZMmQIs2bNcvrnzzas1MPDg4ULF3L//feTkpJCamoqq1atwmazcd1115GUlES/fv246667CAoKYt26dQ06xHbu3ElUVJRz+uijj5p03VmzZmGxWEhOTiYhIYFZs2YB8K9//Ys9e/bwyCOPkJqaSnJKCmsyMtmXX44I/GHqFVwzbhiXjR1BTHQ0//73v08o+2TtDMaDbe7cufTt25eioiL+8Ic/OM9TShEeHs5bb73F1KlTSU5OZujQoezYsQMPDw8WLFjAnXfeSUpKCunp6VRXVzuVSGOdsbfddhvz588nJSWFHTt2OF1JycnJmM1mUlJSTuiMDQkJYdasWQwaNIhBgwbx0EMPERISwn//+1/Wrl3rVPYeHh7OkMiKigqWLl3qdJE1tf1XrVpFUlISY8aM4YknniAsLAyz2czTTz/NmDFjSEpKQkQaPFSKiopITk7m+eefd8r+/PPPs2zZMmdIbF2Y6q9//Wvi4+O5/PLLmTt3LkFBQYDxNnH77beTmprqfNCD0fl+9dVXEx8fzyWXXMLcuXNP+1+t60Pp1asXBQUFzjeI0NBQPv/8c5YsWcLVV1+Nh4dHk9vmjDlZOE79CbgE2AnsAWY2sv8GIA/Y5Jhm1Ns3HdjtmKaf7lo6vLLlOFXInObMsNvtUlxZI7uOlMrmrCLJOFwieWXVYrPZW+yaiYmJsm/fvhYrX9P2aK7wytM6M5VSZmAukA5kA2uVUovlxCEBF4jIHcedGwLMBgYCAqx3nFt0xk+kDoDZbKakpITU1NQTOqo07QMRobjKQl5pDdVWG55uJqKCfQjyccfUguk10tPTSUpKOqNEVpr2zYoVK7jtttsICws757Ka0muVBuwRkX0ASqkPgCuApnyiNx5YKiKFjnOXYrwdvH/Kszoo3bp1a9CR09qMGjXK2WmmOTPsYqQpyCurodZqx8vdTPcQHwK93Vslf9LSpUtb/BqatsXw4cPPqoO9MZqi6LsC9bVTNjC4keN+rZQaAewC7hGRrJOc2/X4E5VStwC3gNEBo9G0Fex2odCh4C02O94eZqJDfQnw0mmCNe2H5uqM/RyIEZFkYClw6uQXxyEir4rIQBEZGB4e3kwiaTRnj80u5JYZeWgOF1fhYTYRG+ZLr3C/VrPiNZrmoikW/SGgW731KMc2JyJSUG/1deDJeueOOu7c5WcqpEbTWlhtdgoqjEySNrvg5+lGRIAPfp76kxNN+6Upd+9aIE4pFYuhuK8FflP/AKVUpIjUDWQ2EdjuWP4W+IdSKtixPg544Jyl1miaGYvNTn55DYXltdhECPByJyLAEx8PreA17Z/Tum5ExArcgaG0twMfisg2pdQjSqm67+LvUkptU0ptBu7CCLfE0Qn7KMbDYi3wSF3H7PmITlPc+PVcmabYYrVzuLiKnUfKyCurwd/LjbgIf2LCfE+q5JsrTfGZyAs6TXFbSFO8Zs0aZz1SUlL49NNPGz2n/v+gsLCQ9PR04uLiSE9Pp6ioaUGHdUkE65L+nRMni7t01aTj6HWa4ubkZHLWWKySXVghv2QXyy9ZxXKwoEKqaq2NlHAi55qm+GzkPRd0muLGOZs0xXXHiogcPnxYwsPDnev1qf8/uO++++Txxx931reuTsXFxWKz2U4rp6+v7wnbdJripvL1TJg3oXmnr2eek0g6TXHLpymuttjIKqzkqqm/5YMPFxLs487lF6Xw+vNPcOHgQS2apvh4Gmtn0GmK23Ka4rpjwUhyV79T/rHHHuOCCy7goosuYufOnc7tn332GdOnTwcapileuXIlvXv35uGHH+bgwYMn3B/NysmeAK6aWs2i/+p+kTd/1bzTV/ef8vqNWWvl5eXy5ptvyrBhw2TYsGHy+uuvS2lpqXN/dHS0c6CCP/7xj5KUlCSlpaWSm5srERERIiJisVikpKRERETy8vKkZ8+ejQ5isWzZMvH09JS9e/eK1WqVsWPHykcffeS8Tl5enqxbt04SExOlvLxcysrKJD4+XjZs2HBKi76+9Td79mxJTk6WyspKycvLk6ioKKf1W5/6lledxbJs2TIJCAiQrKwssdlsMmTIEFmxYoXU1tbK0KFDJTc3V0REPvjgA7nxxhtFRCQyMlKqq6tFRKSoqOikbV5ZY5ED+eWyOatItmQXy1VTr5P3P1jglOWFF14QEZG5c+fKzTffLCIiDzzwgLzzzjvOsuPi4k540/roo49kzJgxjdarjpSUFFm9enWDbadqZ0BWrlwpIiI33nij0zIcOXKkrF27VvLy8mT48OFOWebMmSN/+9vfpKamRmJjY2XNmjUiIlJSUiIWi+WUFn1FRYVUVVWJiMiuXbuk7v93Kov+qaeeamCFP/LII04ZX3vtNbnyyivlySeflFtuueWEc2+88UZ58cUXnevHvwHWb7/S0lIZNWqUdO7cWXx9feWLL74QEZFPP/1UJkyYIJMnT5bU1FS59957nYN/REdHy9///ncREZk/f76zDldffbU8++yzImK8VRQXF0tGRobExcVJfn6+VFRUyJAhQ+SOO+4QEZGkpCT573//KyIi9957b4N7f/Xq1RIfHy++vr7yySefiMix37OiokJKSkqkZ8+eznoFBgY6z7Xb7Q3W8/Ly5JlnnpGUlBQZP368fPjhh863ljqaw6I/f3uaLp3jagkAnaa4MfmaK02xiFBRY8Fis7M7txyzUoT7exLm54mPh7nBgNstkaa4vhzHc6p21mmKDdpqmuLBgwezbds2tm/fzvTp07n00ktZsWIFkydPdr5ZnOz/opRq8BYQFhbGPffcwz333MPPP//MTTfdxKOPPsovv/zSpDZqKuev66aNsHDhQrp27cqUKVN45JFHnJkn63MmaYo3bdpEp06dOmSa4k2bNrFp0ya2bNniVK5ffvklt99+Oxs2bGDQoEHO40uqatmbV87BwirsAp0DvOgd6U9koDfu5hNv+1OlKa67bn0lf6o0xfUpKysjMzOTCy64oMlt0NQ0xXVyZWRkOAeuOVPqpylet25dk8YzPVmqXjgxTXF9ziZN8ZQpU06ZptjNzY1JkyaxYcMG53lnmqZ4/fr1/PjjjwQHB5/R79S3b1/8/PzYunXrKY/r1KmT09WYk5NDREREg/0ZGRncd999XH/99QwbNqxJ7s4zRSt6F6PTFJ+eM0lTnHW0gF1HyzlQUInVLnQO8MTTzUREgBduZzhqz5mkKW6M8vJybrvtNiZNmkRwcHCDfTpN8elpi2mK9+/f7zQEDhw4wI4dO4iJiWHEiBEsWrSIqqoqysrK+Pzzz53nTJw40RmZVD9N8YYNGxgyZAgzZsygT58+bNy4kddff53BgxtLPHBuaEXfRtBpik9OU9IUJ6ekcu0Nt1AmnmzbvIGn//p/9O7kT7CvZ4unKU5NTXUqDIDRo0eTmJhIWloa3bt312mK6ThpileuXOm8BydPnsxLL71EWFgY/fv355prriElJYVLL720gXEzc+ZMli5dSlxcHN999x0zZxpBG97e3sybN49Vq1Zx8803N08Y5UlQjfkPXcnAgQOlLrKgudm+fbvz1dsVZGZmctlll532Va+lWL58+UnHAW2POD9yqqh1fsUa7u+Jn2fHzEOTlJTE4sWLdQbL8ww/P78T3GCN6TKl1HoRGdhYGdqib0XqpynWnD1VtVayCivZ4fjIyc/TjV4RfvQI98Pfq2PmodFpis8/6sKZm9qncSq0Ra9pF4gIpdVW8strqKixYlKKEF8PQv088HRruptLo+kInKlFf96FV4pIh7T4Oio2u5EHPr/cyAPvYTYRGehNiK875jPsXNVoOgJnY5yfV4rey8uLgoICQkNDtbJv49RabRRU1Dr97z4ebnQO8dIpgjXnNSJCQUEBXl5eZ3TeeaXoo6KiyM7OdoZladoWIlBjtVFRY6XaYqRm8PYw4+fphsXNRE4B5JymDI2mo+Pl5eX8qLCpnFeK3t3dXXdmtUGKK2tZuD6b/6w+QGZBJaG+Hlyb1o3fDI6ma5C3q8XTaNo955Wi17QttmSX8M7qTD7bdJgaq52B0cHck34BlyR21h2sGk0zohW9plWpqLHy5S85vLvmIJuzivF2NzOlfxTXDelOQpdAV4un0XRItKLXtDgiwsasYj5cm8Xnmw9TUWujR7gvsy+PZ0r/KAK93V0tokbToWmSoldKXQI8D5iB10VkznH7/w+YAViBPOAmETng2GcDtjgOPSgiTU+DqGnXFJTX8OnGQyxYm8Xu3HK83c1clhzJNYO6MSA6WEfPaDStxGkVvVLKDMwF0oFsYK1SarGI1B/TbCMwUEQqlVJ/wBgc/BrHvioRSW1esTVtFYvNzordeSxcn83SjKNYbEJqtyAen5LEZcmR+Htp612jaW2aYtGnAXtEZB+AUuoD4ArAqehFZFm941cD1zWnkJq2jYiwKauYRRsP8fkvORRW1BLs485vh8RwzaBu9O7s72oRwWaB6hKoKjbm1UX1lkvAWg2WKrDWgLUKLNXGNtsp0vYqM7h5gpvXiXNPf/AKPDZ5Bx1b9gwE/bGXphVpiqLvCmTVW88GTpVH82bg63rrXkqpdRhunTkisuj4E5RStwC3gJGaVNM+2J9fwaKNh1i06RAHCirxcDORHt+JyaldGXFBOB5uraDMbFYoy4Hig1B6GMqPQvkRKM+FMse8/AhUNWFAZqei9gZ3L2Pd7AEnczHZbY4HQ43xUKib204cVrABJjfwjQC/CPDrdGzu39mYB3WDwO7gE3Lya2s0Z0CzdsYqpa4DBgIj622OFpFDSqkewA9KqS0isrf+eSLyKvAqGLlumlMmTfOSU1LF11uOsHjzYTZlFaMUDO0Ryu2je3FJYmcCmts1IwIV+VCwB4oyDYVefBCKDziU+yGwWxueY/YE/06G0gztCdEXGsrUOxi8gupZ10HHrGx37+ZTqnY71JZDdfGxNwbn20MxVBYYD6Syo8ZDKmczVOSCHDd+r7uvofSDukOgYx4cDaG9IKQHePg2j7yaDk9TFP0hoFu99SjHtgYopcYCDwIjRcRp0ojIIcd8n1JqOdAP2Hv8+Zq2y6HiKr7eksNXW3LYcLAYgD6d/Xng0j5MTO1CZGAzfNRkqYLCfZC/Gwp2Q/4eQ7kX7DYUZH38Iw2l1y3NmNdNAV0N5e4V6FpL2GQCrwBjaip2G1QWGoq/JMvxMMsyHmglWZC99sS3koCuxoMstFfDKSgazDqgTnOMptwNa4E4pVQshoK/FvhN/QOUUv2AfwOXiEhuve3BQKWI1CilwoBhGB21mjZOVmElX2/N4cstR9icVQxAfGQA9467gEuTIukZfpaDJNhtULAXjm51TNvgaIahzKj3MhfQ1VBaSVc5FFgchMRCYJThXulomMzgF25MkcmNH1NTZrzVFNQ9BPca862fGG8KdZg9jPaK6OuY4iGiDwTF6L6B85TTKnoRsSql7gC+xQivfFNEtimlHsEYdXwx8BTgB3zkCJmrC6PsC/xbKWXHyH0/57hoHU0bwW4XfjlUwvfbj/Ld9ly255QCkNQ1kD9f0ptfJUYSE3aGroKqIkORH9l6TLHnbjf82GD4qsMuMCzzftdBmEOhh/bUbonG8PSHzknGdDyVhYbSz98N+TuNds76H2xdeOwYdx8I7w3h9R4AneKNNyTdF9ChOa/y0WsaUllrZeXufL7fnssPO3PJK6vBpGBgdAhj4yO4NDGSbiE+py/IaaVvqafYt0Fp9rFjfMKgcyJ0qpsSDKXTEa3ztkR1KeTthNwMyNthzHN3GB3UdfiEGr9J3UOkU6Lx25h1KGx7Quej1wBGGOTevApW7s7jv7vyWLW3gBqrHX9PN0b0Dmds3whGXRBBsK/HyQupLHS4W7YdU+wnWOm9jQ7Qzg6F3inJ6AzVVmPr4xUA3QYZU30qC43f7eg2OPKL8ba15rVjEUNmD0PZd052PAQcD2ifkNavg+ac0RZ9B6ewopaf9uSzYnceK3fnc7jEUMjRoT5c3CeCsX07MSgm5MRQSJsVCh2+9DoL/ehWI8qljuOt9M6JhitGW+ntE5vVcP8c2WI8xI9sNZYrjg18TkCUw/JPPGb9B8dq338bQFv05xEVNVbWHyji530FrNydz9bDJYhAgJcbw3qFccfF4QyPC2vokqkshKxtx/zoR7Yar/knWOnDtJXekTG7GZ22EX2Aq45tLzvaUPEf3Qq7vz0WDurhZ/j7698bneKNPgVNm0Bb9O2ckioL6zILWbO/kNX7C9l6qASbXXAzKfp3D+aiuDCGx4WRHBWEWRwWW511XueC0Va65kyxVDlcPw7lX/fWV1MvFDY4puF91ClBR/60IKey6LWib0eICIeKq9iUVcy6zCLW7C9k+5FSRMDDbCKlWyCDY0NJiwlmQFgtvkU7joUvHt1mRGPUfdJfF/FS/0/YKcn40EijORtEjDDZ4yOtCvbiDJ318HPcawn1Oua19d8caEXfTimvsfJLVjEbs4rZlFXMxoPF5JcbnWVe7iYGRAdzYTdfhgfl0deUhXv+9mOWelXhsYL8uzj+WPHHIl5C48DtFJ2uGk1zUVt5zPqvuz+PbD259d8p3ggBDYnVkT9ngPbRtwPKa6zsyCll2+FSth0uYXNWCbtyy6h7DieFCr/tWswgvzziTIcJrdqPKX8n/HzwWCHuPkZ8dN/LjD9MRLyh1HWkhMaVePhA1ABjqkMESrIb9gsd3QY7vsRp/ZvcjY/lwntDeJ9j89Ce2pV4hmiL3gXkldWw7XAJ2w6XkpFTSsbhUjILKhARQimln/dRhgcVkux1lBh7FoHlezFVHD1WgNnTcLuEX2B0kkb00dEPmo5BbSXk7zJi//N2HJsX7T/W+avMRq4f5wOgj/FfCOlxXruAtEXvAkSEgopadh8tZ09uGbtzy9l9tJzdueVYy/OJVUeIUUcY6JPPdK98okOPElKThbulzDBoijD8meG9odcYx03tmIKijU/mNZqOhocPdEk1pvpYqo1AgvrKP28n7PqmYVI7v04Q0hNCezjmjlxAwbFG2ecpWtGfIxabneyiKjILKsjMr2B3bjl7j5RSlHsQ/+ocolQesaYjDDbn8lv3XLpKDj5eZccKsJnArZtxQ4YMM+ZhFxhWSkAXHb6o0YCRNrqzI3CgPtZaRzK8nUanb+FeY75rScP4fzDyJ4X0cPzXehqZQIO6G4aTd3CH/q9pRd8Eqi02sosqycyvJLOggoP55RTnZmEtPIBnRTZdJI8olUcvlcfF5ny6kI87VnC4EQUFgVGo0J4QMvzYjRba07jJdKeoRnN2uHnUi/0/jupS4yFQsMcxdzwIMhY3DFYA8PA/lgXV+QBwPASCuhuprdsx572iFxGKKy0cKq7icHEVhwtLKc07RG1hNrbSw7iV5+Bbm0ekKqSzKmQsRXQxFeCB43XR0YIWrzAI7o5byIWo424SFRytO480mtbGK6BxNxAYCfecYxschKIDx5YzVxjjCdTHM8B4w/aPNN4MAiKN9YCux7a14YFiOrSir6ixkltWQ25JFQVFRZQXHqa6+Ai2kqNIRR6mqnw8qvMJsxfQSRWRqgoZSwkm1bCD2uruTo13J8S/Cx7BfXEPjW74tA+Mwv089v9pNO0O72Bjikw5cZ+I40Fw4NhDoCTLGMGs9LDRP1B+9MSBYsyexgPAv4sx940w0k7XjSbmG35s3sqGX4dR9EVFhXz/3tOYK/PxqCnA11JIkBQTpkpJoQQvZWn0vEq3AKq9IrD5dcUcmEZ1aFe8Q7uhAro4nuBdcPMJwa2NPqk1Gk0zo5RhnfuEQJd+jR9jszpGCcsxviwvdczLcoyHwaENUJF34ptBHZ6B9R4CjrlvuOHOTbqy2avUYRS9h7JxZd5cbJgoNwdT6ROC1SsCm28i+f4ReAZ2wickEp/gzii/CKNhfULxcfNA2+IajeaMMLtBYFdjotGIRoPaSqNTuCLfGL+4IhfK8xzzXONhcDQDKpYbI6l1G6wV/anwDQyDP+/H7BVEoMlEoKsF0mg0Gg8f8Igxvvw9HTYL1Fa0iBhN+rpGKXWJUmqnUmqPUmpmI/s9lVILHPv/p5SKqbfvAcf2nUqp8c0o+/FCGK9a+oMhjUbTHjG7t1h0z2m1olLKDMwFLgXigalKqfjjDrsZKBKRXsCzwBOOc+MxxphNAC4BXnKUp9FoNJpWoinmbxqwR0T2iUgt8AFwxXHHXAHMdywvBMYoY/DYK4APRKRGRPYDexzlaTQajaaVaIqPviuQVW89Gxh8smMcg4mXAKGO7auPO7fr8RdQSt0C3OJYLVdK7WyS9I0TBuSfw/lthY5SD9B1aat0lLp0lHrAudUl+mQ72kRnrIi8CrzaHGUppdadLLFPe6Kj1AN0XdoqHaUuHaUe0HJ1aYrr5hDQrd56lGNbo8copdyAQKCgiedqNBqNpgVpiqJfC8QppWKVUh4YnauLjztmMTDdsXwl8IMY+Y8XA9c6onJigThgTfOIrtFoNJqmcFrXjcPnfgfwLWAG3hSRbUqpR4B1IrIYeAN4Rym1ByjEeBjgOO5DIAOwAreLiK2F6lJHs7iA2gAdpR6g69JW6Sh16Sj1gBaqS5sbeESj0Wg0zYv+ukij0Wg6OFrRazQaTQenwyl6pdSjSqlflFKblFJLlFJdXC3T2aKUekoptcNRn0+VUkGululsUUpdpZTappSyK6XaXSjc6dKAtCeUUm8qpXKVUltdLcu5oJTqppRappTKcNxbd7taprNFKeWllFqjlNrsqMvfmrX8juajV0oFiEipY/kuIF5EbnWxWGeFUmocRgSTVSn1BICI3O9isc4KpVRfwA78G7hXRNrNCPCOtB27gHSMj/7WAlNFJMOlgp0lSqkRQDnwtogknu74topSKhKIFJENSil/YD0wqT3+Lo5MAr4iUq6UcgdWAneLyOrTnNokOpxFX6fkHfhiDLXdLhGRJSJSN/LxaozvENolIrJdRM7li2dX0pQ0IO0GEfkRIzquXSMiOSKywbFcBmynkS/v2wNiUJe83t0xNZvu6nCKHkAp9ZhSKguYBjzkanmaiZuAr10txHlKY2lA2qVC6ag4Mub2A/7nYlHOGqWUWSm1CcgFlopIs9WlXSp6pdR3SqmtjUxXAIjIgyLSDXgXuMO10p6a09XFccyDGN8hvOs6SU9PU+qi0TQ3Sik/4GPgj8e90bcrRMQmIqkYb+5pSqlmc6u1iVw3Z4qIjG3ioe8CXwGzW1Ccc+J0dVFK3QBcBoyRNt6hcga/S3tDp/Joozj82R8D74rIJ66WpzkQkWKl1DKM1O7N0mHeLi36U6GUiqu3egWww1WynCtKqUuAPwMTRaTS1fKcxzQlDYimlXF0YL4BbBeRZ1wtz7mglAqvi6pTSnljdPw3m+7qiFE3HwO9MSI8DgC3iki7tL4cKSU8MRLEAaxuxxFEk4EXgXCgGNgkIi034lgzo5T6FfAcx9KAPOZaic4epdT7wCiMlLhHgdki8oZLhToLlFIXASuALRj/d4C/iMhXrpPq7FBKJWOM6WHGMMA/FJFHmq38jqboNRqNRtOQDue60Wg0Gk1DtKLXaDSaDo5W9BqNRtPB0Ypeo9FoOjha0Ws0Gk0HRyt6jUaj6eBoRa/RaDQdnP8HNAtH93qjmqYAAAAASUVORK5CYII="
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "RNN could have various form as below:\n",
    "* one to one\n",
    "    - Character or Word prediction model\n",
    "    - e.g.) h → e, love → you\n",
    "* one to many\n",
    "    - Captioning image model\n",
    "    - input: image / output: caption\n",
    "* many to one\n",
    "    - Sentence summary model\n",
    "    - input: sentence / output: summarized word\n",
    "* many to many\n",
    "    - Translator\n",
    "    - input: sentence composed of words\n",
    "    - output: sentence composed of words\n",
    "\n",
    "![form_of_rnn.jpeg](form_of_rnn.jpeg)\n",
    "\n",
    "* Multiple Layer RNN\n",
    "    - using multiple hidden layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Character RNN\n",
    "\n",
    "Design character RNN learns \"hello\", sequence of h→e→l→l→o. For example:\n",
    "* Return 'e' when 'h' is given.\n",
    "* Return 'l' when 'e' is given.\n",
    "* Return 'l' when 'l' is given after 'e'.\n",
    "* Return 'o' when 'l' is given after 'l'.\n",
    "\n",
    "Perform Numerical Transformation for letters above by one-hot encoding:\n",
    "* 'h'→$[1,0,0,0]$\n",
    "* 'e'→$[0,1,0,0]$\n",
    "* 'l'→$[0,0,1,0]$\n",
    "* 'o'→$[0,0,0,1]$\n",
    "\n",
    "(Word can be transformed into numeric as same.)\n",
    "\n",
    "![helloRNN1.png](helloRNN1.png)\n",
    "\n",
    "$$h_t = f(h_{t-1},x_t) = tanh(W_{hh}h_{t-1}+W_{xh}x_t)$$\n",
    "\n",
    "Input size = Output size =4.\n",
    "Set hidden size = 3 (no matter)\n",
    "$\\Rightarrow (3,3)\\times(3,1)+(3,4)\\times(4,1)$\n",
    "\n",
    "\n",
    "* input vector $x$: $4 \\times 1$\n",
    "* $W_{xh}$: $3 \\times 4 \\quad (hidden\\,size) \\times (input\\,size)$\n",
    "* Set hidden size = 3\n",
    "* $h$: $3 \\times 1$\n",
    "* $W_{hh}$: $3 \\times 3 \\quad (hidden\\,size) \\times (hidden\\,size)$\n",
    "\n",
    "![helloRNN2.png](helloRNN2.png)\n",
    "\n",
    "$$y_t = W_{hy}h_t \\qquad \\Rightarrow (4,3)\\times(3,1)=(4,1)$$\n",
    "\n",
    "* $y$: $4 \\times 1$\n",
    "* $W_{hy}$: $4 \\times 3 \\quad (output\\,size) \\times (hidden\\,size)$\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]\n",
    "\n",
    "# One cell RNN input_dim (4) -> output_dim (3)\n",
    "x_data = np.array([[h]], dtype=np.float32)\n",
    "\n",
    "hidden_size = 3\n",
    "rnn = layers.SimpleRNN(units=hidden_size, return_sequences=True, return_state=True)\n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print(x_data, x_data.shape) # x_0\n",
    "print(outputs, outputs.shape) # h_0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-21 22:48:14.437418: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-21 22:48:14.437450: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[1. 0. 0. 0.]]] (1, 1, 4)\n",
      "tf.Tensor([[[ 0.44373775 -0.6493984   0.44392574]]], shape=(1, 1, 3), dtype=float32) (1, 1, 3)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-21 22:48:16.481024: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-21 22:48:16.481058: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-21 22:48:16.481083: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fennecfox38-13UD580-GX30K): /proc/driver/nvidia/version does not exist\n",
      "2021-07-21 22:48:16.481322: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (3). sequence: 5\n",
    "x_data = np.array([[h, e, l, l, o]], dtype=np.float32)\n",
    "print(x_data, x_data.shape)\n",
    "\n",
    "hidden_size = 3\n",
    "rnn = layers.SimpleRNN(units=hidden_size, return_sequences=True, return_state=True)    \n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print(outputs, outputs.shape) # sequence: y[:]\n",
    "print(states, states.shape) # state: y[-1]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]] (1, 5, 4)\n",
      "tf.Tensor(\n",
      "[[[-0.4611585   0.19187419 -0.5106813 ]\n",
      "  [ 0.05471678 -0.6969605  -0.23458369]\n",
      "  [ 0.45338786 -0.86541414 -0.23950171]\n",
      "  [ 0.7239874  -0.8789558  -0.19926643]\n",
      "  [ 0.1068599  -0.87165004 -0.14845414]]], shape=(1, 5, 3), dtype=float32) (1, 5, 3)\n",
      "tf.Tensor([[ 0.1068599  -0.87165004 -0.14845414]], shape=(1, 3), dtype=float32) (1, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ※return_sequence※\n",
    "* return sequence (all past value of hidden layer)\n",
    "* variable ```output``` in example above\n",
    "\n",
    "## ※return_state※\n",
    "* return state (final value of hidden layer)\n",
    "* variable ```state``` in example above\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Many to Many RNN\n",
    "\n",
    "* learning \"hello\" in character unit.\n",
    "* 'h'→'e','e'→'l','l'→'l','l'→'o'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "text = \"hello\"\n",
    "char_vocab = sorted(list(set(text))) # Set eliminates duplicated.\n",
    "vocab_size=len(char_vocab)\n",
    "print(char_vocab)\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(char_vocab)) # Assign unique index to letter\n",
    "print(char_to_index) # Label encoded\n",
    "\n",
    "_tmp = []\n",
    "for ch in text:\n",
    "    _tmp.append(char_to_index[ch])\n",
    "print(\"\\\"hello\\\" is encoded to:\",_tmp)\n",
    "\n",
    "train_X = [_tmp[:4]]\n",
    "train_y = [_tmp[1:]]\n",
    "print(\"train_x:\",train_X,\"train_y\",train_y)\n",
    "\n",
    "seq_length = 4\n",
    "n_samples = 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['e', 'h', 'l', 'o']\n",
      "{'e': 0, 'h': 1, 'l': 2, 'o': 3}\n",
      "\"hello\" is encoded to: [1, 0, 2, 2, 3]\n",
      "train_x: [[1, 0, 2, 2]] train_y [[0, 2, 2, 3]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# One-hot Encoding\n",
    "train_X = to_categorical(train_X)\n",
    "train_y = to_categorical(train_y)\n",
    "print(train_X.shape)\n",
    "print(train_X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 4, 3)\n",
      "[[[0. 1. 0.]\n",
      "  [1. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 1.]]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "n_hidden = 5\n",
    "model = Sequential()\n",
    "model.add(layers.SimpleRNN(n_hidden, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs = 200, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-21 22:48:17.164061: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-21 22:48:17.188042: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 1.2644 - accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2605 - accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2567 - accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2528 - accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2490 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2451 - accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2413 - accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2375 - accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2337 - accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2300 - accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2263 - accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2225 - accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2189 - accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2152 - accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2115 - accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2079 - accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2042 - accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2006 - accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1971 - accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1935 - accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1899 - accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1864 - accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1829 - accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1794 - accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1759 - accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1724 - accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1690 - accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1656 - accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1621 - accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1587 - accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1554 - accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1520 - accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1487 - accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1453 - accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1420 - accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1387 - accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1354 - accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1322 - accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1289 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1257 - accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1225 - accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1193 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1161 - accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1129 - accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1097 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1066 - accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1034 - accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1003 - accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0972 - accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0941 - accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0910 - accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0879 - accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0849 - accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0818 - accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0788 - accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0757 - accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0727 - accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0697 - accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0667 - accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0637 - accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0608 - accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0578 - accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0548 - accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0519 - accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0489 - accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0460 - accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0431 - accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0402 - accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0373 - accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0344 - accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0315 - accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0286 - accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0258 - accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0229 - accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0200 - accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0172 - accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0143 - accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0115 - accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0059 - accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0030 - accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0002 - accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9974 - accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9946 - accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9918 - accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9890 - accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9863 - accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9835 - accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9807 - accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9779 - accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9752 - accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9724 - accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9696 - accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9669 - accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9641 - accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9614 - accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9586 - accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9559 - accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9532 - accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9504 - accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9477 - accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9450 - accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9422 - accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9395 - accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9368 - accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9341 - accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9313 - accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9286 - accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9259 - accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9232 - accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9204 - accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9177 - accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9150 - accuracy: 0.5000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9123 - accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9096 - accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9068 - accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9041 - accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9014 - accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8987 - accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8960 - accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8932 - accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8905 - accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8878 - accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8851 - accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8823 - accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8796 - accuracy: 0.5000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8769 - accuracy: 0.5000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8741 - accuracy: 0.5000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8714 - accuracy: 0.5000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8687 - accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8659 - accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8632 - accuracy: 0.5000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8604 - accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8577 - accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8549 - accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8522 - accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8467 - accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8439 - accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8411 - accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8383 - accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8356 - accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8328 - accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8300 - accuracy: 0.5000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8272 - accuracy: 0.5000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8244 - accuracy: 0.5000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8216 - accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8188 - accuracy: 0.5000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8160 - accuracy: 0.5000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8132 - accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8104 - accuracy: 0.5000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8076 - accuracy: 0.5000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8047 - accuracy: 0.5000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8019 - accuracy: 0.5000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7991 - accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7962 - accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7934 - accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7905 - accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7877 - accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7848 - accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7820 - accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7791 - accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7762 - accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7734 - accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7705 - accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7676 - accuracy: 0.7500\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7647 - accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7618 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7589 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7560 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7531 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7502 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7473 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7444 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7415 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7386 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7357 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7327 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7298 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7269 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7240 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7181 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7152 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7122 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7093 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7064 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7034 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6975 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6887 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6858 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6770 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6740 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff7eff3fee0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "pred = model.predict(train_X)\n",
    "print(pred)\n",
    "print(np.argmax(pred, 2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[0.44261405 0.11810405 0.33264175 0.10664018]\n",
      "  [0.11910401 0.1047893  0.52204674 0.25406003]\n",
      "  [0.13879818 0.05481905 0.6216832  0.1846996 ]\n",
      "  [0.08293605 0.07239868 0.3582268  0.48643845]]]\n",
      "[[0 2 2 3]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It returns \"ello\" when \"hell\" is given.\n",
    "\n",
    "Keep in mind that we use ```softmax``` as activation function in dense layer and wrap it with ```TimeDistributed``` layer\n",
    "\n",
    "## TimeDistributed layer\n",
    "> from [keras.io](https://keras.io/api/layers/recurrent_layers/time_distributed/)\n",
    ">\n",
    ">```tf.keras.layers.TimeDistributed(layer)```\n",
    ">\n",
    ">This wrapper allows to apply a layer to every temporal slice of an input.\n",
    "\n",
    "Many to one model cares only final value ```y[-1]```\n",
    "\n",
    "TimeDistributed layer allows it works as 'many to many models'.\n",
    "Calculate cost in all output node by time.\n",
    "\n",
    "keras would calculate cose in many to one method if dense layer is not wrapped with TimeDistributed Layer.\n",
    "\n",
    "![TimeDistributed.png](TimeDistributed.png)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Many to one RNN\n",
    "\n",
    "Sequence classification\n",
    "\n",
    "eg. classify polarity of sentence\n",
    "* sequence: sentence\n",
    "* tokens: word\n",
    "\n",
    "['This movie is good']\n",
    "\n",
    "↓ Tokenization\n",
    "\n",
    "['This','movie','is','good']\n",
    "\n",
    "↓ Classification\n",
    "\n",
    "Positive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# example data\n",
    "words = ['good', 'bad', 'worse', 'so good']\n",
    "y_data = [[1],[0],[0],[1]]\n",
    "\n",
    "# creating a token dictionary\n",
    "# join all words and eliminate duplicates (using set) and add '<pad>'\n",
    "# make dictionary bidirectionally\n",
    "char_set = ['<pad>'] + sorted(list(set(''.join(words))))\n",
    "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
    "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
    "\n",
    "print(char_set)\n",
    "print(idx2char)\n",
    "print(char2idx)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['<pad>', ' ', 'a', 'b', 'd', 'e', 'g', 'o', 'r', 's', 'w']\n",
      "{0: '<pad>', 1: ' ', 2: 'a', 3: 'b', 4: 'd', 5: 'e', 6: 'g', 7: 'o', 8: 'r', 9: 's', 10: 'w'}\n",
      "{'<pad>': 0, ' ': 1, 'a': 2, 'b': 3, 'd': 4, 'e': 5, 'g': 6, 'o': 7, 'r': 8, 's': 9, 'w': 10}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# converting sequence of tokens to sequence of indices\n",
    "# use lambda function to mapping\n",
    "# charactor to index / length\n",
    "x_data = list(map(lambda word : [char2idx.get(char) for char in word], words))\n",
    "x_data_len = list(map(lambda word : len(word), x_data))\n",
    "\n",
    "print(x_data)\n",
    "print(x_data_len)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]\n",
      "[4, 3, 5, 7]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# padding the sequence of indices\n",
    "max_sequence = 10\n",
    "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence,\n",
    "                       padding = 'post', truncating = 'post')\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "# checking data\n",
    "print(x_data)\n",
    "print(y_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 6  7  7  4  0  0  0  0  0  0]\n",
      " [ 3  2  4  0  0  0  0  0  0  0]\n",
      " [10  7  8  9  5  0  0  0  0  0]\n",
      " [ 9  7  1  6  7  7  4  0  0  0]]\n",
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating model\n",
    "\n",
    "```np.eye(x)```: Identity Matrix $I_x$\n",
    "\n",
    "### Embedding Layer\n",
    "* Dimension Reduction Embedding\n",
    "* One-hot encoded would be sparse matrix (most of its value is 0) which is wasting memory.\n",
    "* Embedding vector reduce dimension while explicating similarity between words.\n",
    "\n",
    "* Realize embedding vector using CBOW, skip-gram model\n",
    "\n",
    "![embeddinglayer.png](embeddinglayer.png)\n",
    "![embeddinglayer2.png](embeddinglayer2.png)\n",
    "\n",
    "### CBOW: Continuous bag of words\n",
    "* CBOW is neuron network model predicting the central word from the surrounding words. \n",
    "* Learning central and surrounding word dataset generated by the sliding window with changing central dataset.\n",
    "\n",
    "![SlidingWindow.png](SlidingWindow.png)\n",
    "\n",
    "* Summarizing surrounding words while learning model that explains central word using the surrounding word.\n",
    "\n",
    "* Hidden layer value made by dimension reduction becomes embedding vector that explains central word well.\n",
    "\n",
    "### Projection Layer\n",
    "\n",
    "Below is example of analyzing \"cat sat on\"\n",
    "* Size of projection layer ($M=5$) is usually set smaller than output layer.\n",
    "* $V$ is length of one-hot vector.\n",
    "* $W$ is weight of input contributing projection\n",
    "* $V_{cat}$ and $V_{on}$ can be merged into M since these have one-hot structure.\n",
    "\n",
    "![ProjectionLayer.png](ProjectionLayer.png)\n",
    "\n",
    "\n",
    "### using class ```tensorflow.keras.layers.Embedding```\n",
    "\n",
    "```python\n",
    "# from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=input_dim,\n",
    "                                 output_dim=output_dim,\n",
    "                                 mask_zero=True,\n",
    "                                 input_length=max_sequence,\n",
    "                                 embedding_initializer=keras.initializer.Constant(one_hot)))\n",
    "```\n",
    "\n",
    "Note that:\n",
    "* ```input_dim```: size of one_hot vector\n",
    "* ```output_dim```: size of output on embedding\n",
    "* use option ```mask_zero=True``` in order to prevent from learning zero-padded part\n",
    "\n",
    "### ```loss='sparse_categorical_crossentropy'``` (손실함수: 희소범주 교차엔트로피)\n",
    "\n",
    "* Use 'Sparse Categorical Cross Entropy function as loss function\n",
    "* 'Sparse Categorical Cross Entropy' function is used when **non-'one-hot encoded' output is given**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# creating SimpleRNN for \"many to one\" classification\n",
    "input_dim = len(char2idx)\n",
    "output_dim = len(char2idx)\n",
    "one_hot = np.eye(len(char2idx)) # Identity Matrix\n",
    "hidden_size = 10\n",
    "num_classes = 2 # Calculate probabilites whether it is 0 or 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True, input_length=max_sequence, embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_size))\n",
    "model.add(layers.Dense(units=num_classes))\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 11)            121       \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 10)                220       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 363\n",
      "Trainable params: 363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "x_data\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 6,  7,  7,  4,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  2,  4,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [10,  7,  8,  9,  5,  0,  0,  0,  0,  0],\n",
       "       [ 9,  7,  1,  6,  7,  7,  4,  0,  0,  0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_data, y_data, epochs=30)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5892 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5675 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5462 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5251 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5042 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4833 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4624 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4412 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4199 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3981 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3757 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3527 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3287 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3094 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2968 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2839 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2705 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2583 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2552 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2520 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2485 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2447 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2408 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2366 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2322 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2276 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2227 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2176 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2123 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2067 - accuracy: 1.0000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1)\n",
    "print(y_data, yhat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]] [1 0 0 1]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}